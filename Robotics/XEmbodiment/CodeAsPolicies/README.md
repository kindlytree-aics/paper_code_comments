# Code as Policies:

https://code-as-policies.github.io/

This paper presents code as policies: a robot-centric formalization of language model generated programs (LMPs) that can represent reactive policies (e.g., impedance controllers), as well as waypoint-based policies (vision-based pick and place, trajectory-based control), demonstrated across multiple real robot platforms.

## 问题1：什么是Reactive Policy？

回答：因为它只依赖当前的：实际位置/速度（来自传感器），与目标位置的偏差，当前检测到的力/接触情况，然后实时计算出下一步的控制命令（如关节力矩、末端速度），没有学习、记忆或优化过程，因此称为反应式策略。

## 问题2：LMP具体是指什么？以及如何通过LLM实现代码生成？直接用训练好的通用大模型可以吗？

回答：
we use the term LMP to refer to any program generated by a language model and executed on a system. 以及LMP为大模型生成的程序代码片段，可以在系统上执行。

为什么能够采用Few-shot prompts来实现LMP，主要有两个关键原因：
1、预训练大模型的「上下文学习」能力强，LLM（如 GPT-3/4、Codex）通过大规模预训练，在语言建模任务中学会了模式匹配、规则泛化，即使没有参数微调，也能从几个上下文对话中“学会”新任务结构。
OpenAI Codex 是OpenAI开发的一种大型语言模型，专门用于理解自然语言并生成代码。它是 GPT-3 的后续版本，针对 编程任务进行了微调，可以理解人类的自然语言指令，并将其翻译为多种编程语言中的代码。
2、few-shot 示例提供了「隐式的任务结构引导」，示例（任务描述到程序输出）构成一种“软约束”或“任务程序模板”，大模型基于模式拟合来自动生成当前 prompt 的输出。

Few-shot prompting 是一种利用在输入提示（Prompt）中包含少量示例（Exemplars/Shots,prompt和response的pair对） 的技术。这些示例向大模型演示了期望的任务、格式、风格或推理过程。
模型通过分析这些上下文中的示例（进行所谓的 上下文学习 In-context Learning），理解用户的意图和要求，并模仿这些模式来生成符合特定目标的输出，从而有效引导和约束了模型的行为，
使其在没有额外训练的情况下适应特定的任务。它利用的是模型的模式识别和泛化能力，而不是让模型从几个例子中学习新的事实性知识。
虽然这些样例是上下文的一部分，但它们通常是在实际提问之前一次性提供给模型的，作为初始设定或指令的一部分，而不是动态地成为正在进行中的多轮对话历史的一部分。
因此需要有模型API才能使用，一般的提供的大模型服务的对话管理是模型服务后台提供的，不能直接使用来做LMP服务，也可以采用开源的大模型做私有部署后调用API来实现LMP功能。

每一个LMP一般提供5-20个prompts的样例（few-show prompts）作为上下文提供给大模型，大模型根据这些上下文生成特定的python代码，如子程序，这些子程序可以完成不同的功能，如完成环境感知接口的调用，生成动作轨迹，或控制元语序列等。
下面针对不同的语言生成能力方面分别进行描述。（以下代码前一段为prompt response examples作为对话上下文，后面段落的代码中#号后面的为prompt，紧接着的为response.

## 问题3：LMP在语言生成方面的能力的具体表现有哪些？

具体的表现有：在低层次（low-level）的代码生成方面的能力和在高层次(high-level)的代码生成方面的能力：

### Low-Level LMP

- 根据特定语言以及任务逻辑描述生成代码语句的能力

```
#Python script
#get the variable a.
ret_val=a

#find the sum of variables a and b.
ret_val = a + b

# see if any number is divisible by 3 in a list called xs.
ret_val = any(x%3==0 for x inx s)
```

根据特定语言的第三方库的使用，给出示例的基础上，生成更多的基于第三方库的更多逻辑定义的代码片段能力
如下的基于python的numpy库的代码逻辑生成能力示例

```
import numpy as np
# move all points in pts_np toward the right.
ret_val=pts_np+[0.3,0]
#move a pt_np toward the top.
ret_val=pt_np+[0,0.3]

#get the left most point in pts_np.
ret_val=pts_np[np.argmin(pts_np[:,0]),:]

#get the center of pts_np.
ret_val=np.mean(pts_np,axis=0)

#the closest point in pts_np to pt_np.
ret_val = pts_np[np.argmin(np.sum((pts_np-pt_np)**2,axis=1))]
```

根据样例中提供的自定义的感知或其他任务定义接口，根据任务逻辑生成自定义接口调用的能力，而且能将参数进行合理的具体化。

使用新的感知接口，这些接口为系统实现时自定义的，通过prompts examples提供让模型从上下文中学习

```
from utils import get_pos,put_first_on_second
#move the purple bowl toward the left.
target_pos=get_pos(’purplebowl’)+[-0.3,0]
put_first_on_second(’purplebowl’,target_pos)


objs=[’blue bowl’,’red block’,’red bowl’,’blue block’]
#move the red block a bit to the right.
target_pos=get_pos(’redblock’)+[0.1,0]
put_first_on_second(’redblock’,target_pos)

#put the blue block on the bowl with the same color.
put_first_on_second(’blueblock’,’bluebowl’)
```

语言推理能力（language reasoning）

```
objs = [’blue bowl’, ’red block’, ’red bowl’, ’blue block’]
# the bowls.
ret_val = [’blue bowl’, ’red bowl’]

# sea-colored block.
ret_val = ’blue block’
# the other block.
ret_val = ’red block
```

### High-Level LMP

- 代码if-else，while循环等控制语句的生成能力

```
# while the red block is to the left of the blue bowl, move it to the
right 5cm at a time.
while get_pos(’red block’)[0] < get_pos(’blue bowl’)[0]:
    target_pos = get_pos(’red block’) + [0.05, 0]
    put_first_on_second(’red block’, target_pos)
```

- 代码组合能力
如下的两段prompt，前一段的代码的prompt中定义了一个函数接口`parse_obj`的调用，该函数尚未实现
第二段就定义了函数`parse_ojb`LMP的逻辑
这样就可以通过组合的代码实现函数式的编程范式，代码逻辑结构也更加清晰整洁
```
objs = [’red block’, ’blue bowl’, ’blue block’, ’red bowl’]
# while the left most block is the red block, move it toward the right.
block_name = parse_obj(’the left most block’)
while block_name == ’red block’:
target_pos = get_pos(block_name) + [0.3, 0]
put_first_on_second(block_name, target_pos)
block_name = parse_obj(’the left most block’)


objs = [’red block’, ’blue bowl’, ’blue block’, ’red bowl’]
# the left most block.
block_names = [’red block’, ’blue block’]
block_positions = np.array([get_pos(name) for name in block_names])
left_block_name = block_names[np.argmin(block_positions[:, 0])]
ret_val = left_block_name
```  
- 程序代码嵌套生成
可以在代码生成的代码串中生成未定义的函数，在进行解析时，如果碰到未定义的函数，将调用生成该函数实现的LMP去实现代码的生成，这里用到了python的exec和ast机制，具体的参考下面的问题4的详细介绍。

### 问题4：不同的LMP的嵌套调用具体如何实现？

In Python, we implement hierarchical function generation by parsing a code block’s abstract syntax tree and checking for
functions that do not exist in the given scope. We use the function generating LMP to write these undefined functions and add them
to the scope. This procedure is repeated on the generated function body, hierarchically creating new functions in a depth-first manner.

可以看成是采用的基于深度优先的代码逻辑拓扑图遍历机制，[示例参考代码文件](./Experiment_ Robot Code-Gen Benchmark.ipynb)中的`lmp_fgen`函数
exec仅注册函数名到作用域，不会立即执行函数体。

较为复杂代码生成的特性：
- 延迟执行（Lazy Execution）：仅注册函数定义，不立即执行函数体，避免因未定义子函数导致立即错误。
- 静态依赖分析：通过AST解析 静态识别 函数依赖关系，无需动态运行代码。
- 作用域动态扩展：通过merge_dicts合并作用域，确保递归生成的子函数对父函数可见。

一般父函数的exec会调用两次：
- 一次是还没有生成子函数的代码时，一次是所有的子函数的代码都生成后更新到gvars字典后通过exec再次调用生成完成的可执行代码
```
# 第一次调用仅注册父函数到作用域（lvars），不执行函数体。
f_success = True
try:
    exec_safe(f_src, gvars, lvars)
    f = lvars[f_name]
except Exception as e:
    print(e)
    f = lambda *args, **kargs: None   
    f_success = False 
```
- 在子函数可见的作用域中 重新定义父函数，确保其函数体能正确引用子函数。

```
if recurse and f_success:
    # recursively define child_fs in the function body if needed
    f_def_body = astunparse.unparse(ast.parse(f_src).body[0].body)
    potential_child_fs, potential_child_f_sigs = {}, {}
    f_parser = FunctionParser(potential_child_fs, potential_child_f_sigs)
    f_parser.visit(ast.parse(f_def_body))
    for potential_child_f_name, potential_child_f_sig in potential_child_f_sigs.items():
    if potential_child_f_name in potential_child_fs:
        potential_child_fs[potential_child_f_name] = potential_child_f_sig

    child_fs, child_f_srcs = {}, {}
    for child_f_name, child_f_sig in potential_child_fs.items():
    all_vars = merge_dicts([context_vars, child_fs])
    if not var_exists(child_f_name, all_vars):
        child_f, child_f_src = lmp_fgen(
            prompt, child_f_name, child_f_sig, 
            stop_tokens=stop_tokens, 
            context_vars=all_vars, 
            bug_fix=bug_fix,
            log=False, 
            recurse=True,
            return_src=True,
            query_kwargs=query_kwargs
        )

        child_fs[child_f_name] = child_f
        child_f_srcs[child_f_name] = child_f_src

    if len(child_fs) > 0:
    # redefine parent f so newly created child_fs are in scope
    # child_fs为子函数返回的结果
    # 通过exec_safe将生成的代码注入到gvars（全局变量）和lvars（局部变量）中，使得生成的函数在后续调用中可见。
    gvars = merge_dicts([context_vars, child_fs])
    lvars = {}
    
    exec_safe(f_src, gvars, lvars)
    
    f = lvars[f_name]
```
- 调用触发
```
parent_func = lvars[f_name]  # 通过函数名获取函数对象
parent_func()  # 实际执行函数体
```

# exec仅注册函数名到作用域，不会立即执行函数体。
def exec_safe(code_str, gvars=None, lvars=None):
    banned_phrases = ['import', '__']
    for phrase in banned_phrases:
        assert phrase not in code_str
  
    if gvars is None:
        gvars = {}
    if lvars is None:
        lvars = {}
    empty_fn = lambda *args, **kwargs: None
    custom_gvars = merge_dicts([
        gvars,
        {'exec': empty_fn, 'eval': empty_fn}
    ])
    try:
        exec(code_str, custom_gvars, lvars)
    except Exception as e:
        print(f'Error executing code:\n{code_str}')
        raise e
```

### 问题5：Code as Policys的特殊性和问题2中的LMP的代码生成能力有什么不同和特殊性？优势体现在什么地方？

回答：特殊性是面向机器人的策略代码生成这样的领域，其中感知和控制的接口可以作为样例提供给特定的LMP（如调用感知的目标检测的已有算法和API等），以实现约束或背景条件生成。
具体优势体现在：
1、可以扩展更多的自然语言的任务描述，而不是系统hard code的固定任务；   
2、通过开放词汇的感知系统（如Open-Vocab Detector）可以将任务泛化到更多的目标和场景；  
3、不需要额外的数据收集和模型训练
总之，LMP集成了大语言模型在语言语义上的多种能力，如语言丰富多样的表达能力，多语言支撑能力，语言推理，常识知识和上下文丰富语义表达能力。

## 附录：大模型对话历史的管理和实现

answer from Gemini 2.5 Pro Preview 03-25

是的，您的理解非常正确！

为了让大模型能够理解和处理多轮对话，**通常会采用一种结构化的、通用的格式来表示对话历史**。这种格式最核心的部分就是**区分不同发言者的角色（Role）**。

最常见的角色包括：

1. **`system` (系统)**:

   * 用于设定模型的行为、个性、背景知识或遵循的规则。
   * 通常是对话的第一个消息，或者在整个对话中保持不变的指令。
   * 例如："你是一个乐于助人的助手。" 或 "你是一位精通莎士比亚戏剧的专家，请用复古的语言回答。"
   * 它帮助设定对话的基调和约束。
2. **`user` (用户)**:

   * 代表与模型交互的人类用户的输入。
   * 这是模型需要回应或处理的信息。
3. **`assistant` (助手/模型)**:

   * 代表模型自身之前的回复。
   * 这部分历史让模型知道它之前说了什么，以保持对话的连贯性。

**工作原理：**

在每次需要模型生成新的回复时，通常会将**整个结构化的对话历史**（包括系统消息、过去的用户输入和模型回复）按照时间顺序组合起来，作为输入（Prompt）传递给模型。模型根据这个完整的上下文来理解当前的对话状态，并生成下一个 `assistant` 角色的回复。

**示例说明：**

假设一个简单的对话场景：用户询问天气，然后追问明天的天气。传递给模型 API 的对话历史（通常是类似 JSON 的格式）可能如下所示：

**第一次调用 (用户首次提问):**

```json
[
  {
    "role": "system",
    "content": "你是一个天气预报助手。"
  },
  {
    "role": "user",
    "content": "今天北京天气怎么样？"
  }
]
```

*模型根据以上输入，生成回复，例如："今天北京晴朗，气温 25 摄氏度。"*

**第二次调用 (用户追问):**

在用户问 "那明天呢？" 之后，发送给模型的输入会包含之前的整个交流历史：

```json
[
  {
    "role": "system",
    "content": "你是一个天气预报助手。"
  },
  {
    "role": "user",
    "content": "今天北京天气怎么样？"
  },
  {
    "role": "assistant", // 这是模型上一轮的回复
    "content": "今天北京晴朗，气温 25 摄氏度。"
  },
  {
    "role": "user", // 这是用户最新的问题
    "content": "那明天呢？"
  }
]
```

*模型根据这个包含完整历史的输入，就能理解 "明天呢？" 是在询问北京明天的天气，并生成相应的回复，例如："明天北京预计多云转阴，气温 22-28 摄氏度。"*

**重要性：**

* **区分发言者:** `role` 字段清晰地告诉模型哪部分是指令、哪部分是用户说的、哪部分是自己之前说的。
* **保持上下文连贯:** 允许模型理解指代关系（如 "那明天呢？" 指的是 "北京明天的天气"）和对话流程。
* **控制模型行为:** `system` 角色是进行 Prompt Engineering 和设定模型行为的关键工具。

**注意：**

* 虽然 `system`, `user`, `assistant` 是最常见的角色标签（例如 OpenAI API 使用这些），但不同的模型或 API 提供商可能会使用稍微不同的术语（例如，有些可能用 `model` 代替 `assistant`）。
* 一些更复杂的场景，比如引入了工具调用（Function Calling / Tool Use），可能会有额外的角色，如 `tool` 或 `function`，用来表示工具的调用请求和返回结果。
* 像 **ChatML (Chat Markup Language)** 就是一个旨在标准化这种对话格式的尝试。

总而言之，使用带有 `role` 标签的结构化格式来管理对话历史，是当前大模型处理多轮对话的标准和有效实践。
